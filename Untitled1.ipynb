{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8PwTjBZYMQxF2Tdm75lH2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohanpeerla/Module-4-Lab-1/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1.Try this on a real dataset like the Sonar dataset or the Banknote Dataset and show the error plot."
      ],
      "metadata": {
        "id": "Qi9SrfSDADFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The learning rate is a crucial hyperparameter in training machine learning models, including SGD-based classifiers like SGDClassifier. A very high learning rate can lead to overshooting, causing the algorithm to diverge instead of converging. On the other hand, a very low learning rate may result in slow convergence.\n",
        "#You can experiment with different learning rates to observe their impact on convergence. Here's an example where you can vary the learning rate and observe the number of iterations:\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Sonar dataset using fetch_openml\n",
        "data = fetch_openml(name='sonar', version=1)\n",
        "X = data.data.astype(float)\n",
        "y = (data.target == 'M').astype(int)  # Convert labels to binary (M:1, R:0)\n",
        "\n",
        "# Ensure there are at least two unique classes\n",
        "unique_classes = np.unique(y)\n",
        "if len(unique_classes) < 2:\n",
        "    print(\"The dataset should contain at least two classes.\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perceptron algorithm\n",
        "perceptron = Perceptron(random_state=42)\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Plot the error over iterations\n",
        "plt.plot(range(1, len(perceptron.errors_) + 1), perceptron.errors_, marker='o')\n",
        "plt.title('Perceptron Model Error over Iterations')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Number of Misclassifications')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "3QY9D4av9u7V",
        "outputId": "2d5d0447-9eca-4b02-a455-a73c83f5d3c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset should contain at least two classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1c61b807af55>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Perceptron algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mperceptron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mperceptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_more_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         return self._fit(\n\u001b[0m\u001b[1;32m    895\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         self._partial_fit(\n\u001b[0m\u001b[1;32m    684\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    635\u001b[0m             )\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    638\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one; got %d class\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2.Increase/decrease the learning rate to see how many iterations will be take to coverge. Does it even converge on a huge learning rate?"
      ],
      "metadata": {
        "id": "qltIZJE3ASzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "flc4_6MF4l__",
        "outputId": "e2dd805a-bcca-4d58-8d01-ba8aae32a8b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-08e602e4e410>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msgd_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[1;32m    418\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mthis\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \"\"\"\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This SGDClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = fetch_openml(name='sonar', version=1)\n",
        "X = data.data.astype(float)\n",
        "y = (data.target == 'M').astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "sgd_classifier = SGDClassifier(random_state=42)\n",
        "sgd_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = sgd_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "errors = np.sum(y_test != y_pred)\n",
        "total_samples = len(y_test)\n",
        "\n",
        "plt.bar(['Correct', 'Incorrect'], [total_samples - errors, errors], color=['green', 'red'])\n",
        "plt.title('SGDClassifier Model Accuracy')\n",
        "plt.xlabel('Prediction Accuracy')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "3.#Take a toy dataset that is not linearly separable and run the perceptron algorithm on it. What happens? Note your observations. An example is given below."
      ],
      "metadata": {
        "id": "3jJ6aJdY_UUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Toy dataset\n",
        "X = np.array([\n",
        "    [-2, 4, -1],\n",
        "    [4, 1, -1],\n",
        "    [1, 6, -1],\n",
        "    [2, 4, -1],\n",
        "    [6, 2, -1],\n",
        "])\n",
        "\n",
        "features = X[:, :-1]\n",
        "labels = X[:, -1]\n",
        "\n",
        "def perceptron_algorithm(features, labels, learning_rate=1, epochs=100):\n",
        "    weights = np.zeros(len(features[0]))\n",
        "    errors = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        error = 0\n",
        "        for i in range(len(features)):\n",
        "            prediction = np.dot(features[i], weights)\n",
        "            prediction = 1 if prediction > 0 else -1\n",
        "\n",
        "            update = learning_rate * (labels[i] - prediction)\n",
        "            weights += update * features[i]\n",
        "\n",
        "            error += int(update != 0)\n",
        "\n",
        "        errors.append(error)\n",
        "\n",
        "    return weights, errors\n",
        "\n",
        "\n",
        "weights, errors = perceptron_algorithm(features, labels)\n",
        "\n",
        "for i in range(len(features)):\n",
        "    color = 'red' if labels[i] == 1 else 'blue'\n",
        "    plt.scatter(features[i, 0], features[i, 1], s=120, marker='_', linewidths=2, color=color)\n",
        "\n",
        "x_values = np.linspace(-2, 8, 10)\n",
        "y_values = -(weights[1] * x_values + weights[2]) / weights[0]\n",
        "plt.plot(x_values, y_values, 'g--', label='Decision Boundary')\n",
        "\n",
        "plt.title('Perceptron Algorithm on Toy Dataset')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "csI3e6lW_hqL",
        "outputId": "aad0b68b-2f4e-48ca-be4e-b5403ffbbbf7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3f3e44fa27bb>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mx_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0my_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_values\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Decision Boundary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAXFklEQVR4nO3da4xUhdnA8WfBslLdXYGCsrBQvBUVId6DaCtKtcQY9QM1Blu0xla7XnBrYvELkrYsvVEbaxC0wX4opReD2qZIqRGIaamAIUGNFxQDXVRsqzsLHwbDzvvBV155C5bZfWbH2f5+yUmc2XPmPCc6zn/PnJ2pK5VKpQAASDCg2gMAAP2HsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0hzR1zvs7u6OnTt3RkNDQ9TV1fX17gGAHiiVStHV1RXNzc0xYMChz0v0eVjs3LkzWlpa+nq3AECCHTt2xOjRow/58z4Pi4aGhoj4YLDGxsa+3j0A0AOFQiFaWlr2v44fSp+HxYdvfzQ2NgoLAKgx/+kyBhdvAgBphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABpyg6Ljo6OuO6662LYsGExePDgOP3002Pjxo2VmA0AqDFlfaT3u+++G1OmTImpU6fGypUrY/jw4fHqq6/GkCFDKjUfAFBDygqL73//+9HS0hJLly7df9+4cePShwIAalNZYfHEE0/EZZddFjNmzIi1a9fGqFGj4pvf/GbcdNNNh9ymWCxGsVjcf7tQKPR8WviEW7jwg6Wn2to+WABqVVlh8frrr8eiRYuira0t7rnnntiwYUPcfvvtMWjQoJg1a9ZBt2lvb4958+alDAufdIVCREdH77YHqGVlhUV3d3ecffbZMX/+/IiIOOOMM+L555+PBx988JBhMWfOnGj7yK9gH36fO/RHjY0Ro0b1bnuAWlZWWIwcOTJOPfXUA+475ZRT4tFHHz3kNvX19VFfX9+z6aDGeCsD+G9X1p+bTpkyJV5++eUD7nvllVdi7NixqUMBALWprLC48847Y/369TF//vzYunVrLFu2LJYsWRKtra2Vmg8AqCFlhcU555wTK1asiF/96lcxYcKE+M53vhP33XdfzJw5s1LzAQA1pK5UKpX6coeFQiGampqis7MzGl2pBgA14XBfv31XCACQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQpqywuPfee6Ouru6AZfz48ZWaDQCoMUeUu8Fpp50Wf/7zn//vAY4o+yEAgH6q7Co44ogj4rjjjqvELABAjSv7GotXX301mpub4/jjj4+ZM2fG9u3bP3b9YrEYhULhgAUA6J/KCovzzjsvHnnkkXjyySdj0aJFsW3btrjwwgujq6vrkNu0t7dHU1PT/qWlpaXXQwMAn0x1pVKp1NON33vvvRg7dmwsXLgwbrzxxoOuUywWo1gs7r9dKBSipaUlOjs7o7Gxsae7BgD6UKFQiKampv/4+t2rKy+POeaYOPnkk2Pr1q2HXKe+vj7q6+t7sxsAoEb06nMsdu/eHa+99lqMHDkyax4AoIaVFRZ33XVXrF27Nt544434y1/+EldffXUMHDgwrr322krNBwDUkLLeCvn73/8e1157bfzzn/+M4cOHxwUXXBDr16+P4cOHV2o+AKCGlBUWy5cvr9QcAEA/4LtCAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASNOrsFiwYEHU1dXF7Nmzk8YBAGpZj8Niw4YNsXjx4pg4cWLmPABADetRWOzevTtmzpwZDz30UAwZMiR7JgCgRh3Rk41aW1vj8ssvj2nTpsV3v/vdj123WCxGsVjcf7tQKPRklxERsXDhB0tPtbV9sAA953kIfJyyw2L58uXx3HPPxYYNGw5r/fb29pg3b17Zgx1MoRDR0dG77YHe8TwEPk5ZYbFjx4644447YvXq1XHkkUce1jZz5syJto/8elIoFKKlpaW8Kf9XY2PEqFE92nT/9kDveB4CH6euVCqVDnflxx57LK6++uoYOHDg/vv27dsXdXV1MWDAgCgWiwf87GAKhUI0NTVFZ2dnNPo/DADUhMN9/S7rjMUll1wSW7ZsOeC+G264IcaPHx933333f4wKAKB/KyssGhoaYsKECQfcd9RRR8WwYcP+7X4A4L+PT94EANL06M9NP2rNmjUJYwAA/YEzFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQpKywWLVoUEydOjMbGxmhsbIzJkyfHypUrKzUbAFBjygqL0aNHx4IFC2LTpk2xcePGuPjii+PKK6+MF154oVLzAQA1pK5UKpV68wBDhw6NH/7wh3HjjTce1vqFQiGampqis7MzGhsbe7NrAKCPHO7r9xE93cG+ffvit7/9bezZsycmT558yPWKxWIUi8UDBgMA+qeyL97csmVLHH300VFfXx8333xzrFixIk499dRDrt/e3h5NTU37l5aWll4NDAB8cpX9VsjevXtj+/bt0dnZGb/73e/i4YcfjrVr1x4yLg52xqKlpcVbIQBQQw73rZBeX2Mxbdq0OOGEE2Lx4sWpgwEAnxyH+/rd68+x6O7uPuCMBADw36usizfnzJkT06dPjzFjxkRXV1csW7Ys1qxZE6tWrarUfABADSkrLHbt2hVf/epX480334ympqaYOHFirFq1Kr74xS9Waj4AoIaUFRY///nPKzUHANAP+K4QACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0pQVFu3t7XHOOedEQ0NDjBgxIq666qp4+eWXKzUbAFBjygqLtWvXRmtra6xfvz5Wr14d77//flx66aWxZ8+eSs0HANSQulKpVOrpxu+8806MGDEi1q5dG5///OcPa5tCoRBNTU3R2dkZjY2NPd01ANCHDvf1+4je7KSzszMiIoYOHXrIdYrFYhSLxQMGAwB6ZuHCD5aeamv7YKmUHodFd3d3zJ49O6ZMmRITJkw45Hrt7e0xb968nu4GAPiIQiGio6N321dSj8OitbU1nn/++XjmmWc+dr05c+ZE20fSqFAoREtLS093CwD/1RobI0aN6t32ldSjayxuvfXWePzxx2PdunUxbty4srZ1jQUA1J6KXGNRKpXitttuixUrVsSaNWvKjgoAoH8rKyxaW1tj2bJl8fjjj0dDQ0O89dZbERHR1NQUgwcPrsiAAEDtKOutkLq6uoPev3Tp0rj++usP6zG8FQIAtadib4UAAByK7woBANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgTdlhsW7durjiiiuiubk56urq4rHHHqvAWABALSo7LPbs2ROTJk2KBx54oBLzAAA17IhyN5g+fXpMnz69ErMAADWu7LAoV7FYjGKxuP92oVCo9C4BOISFCz9Yeqqt7YMFDqXiYdHe3h7z5s2r9G4AOAyFQkRHR++2h49T8bCYM2dOtH0kbwuFQrS0tFR6twAcRGNjxKhRvdsePk7Fw6K+vj7q6+srvRsADoO3Mqg0n2MBAKQp+4zF7t27Y+vWrftvb9u2LTZv3hxDhw6NMWPGpA4HANSWssNi48aNMXXq1P23P7x+YtasWfHII4+kDQYA1J6yw+Kiiy6KUqlUiVkAgBrnGgsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAIE3Fv930//vwUzsLhUJf7xoA6KEPX7f/06dv93lYdHV1RURES0tLX+8aAOilrq6uaGpqOuTP60p9/MUf3d3dsXPnzmhoaIi6urq0xy0UCtHS0hI7duyIxsbGtMf9JOnvx+j4al9/P0bHV/v6+zFW8vhKpVJ0dXVFc3NzDBhw6Csp+vyMxYABA2L06NEVe/zGxsZ++R/LR/X3Y3R8ta+/H6Pjq339/RgrdXwfd6biQy7eBADSCAsAIE2/CYv6+vqYO3du1NfXV3uUiunvx+j4al9/P0bHV/v6+zF+Eo6vzy/eBAD6r35zxgIAqD5hAQCkERYAQBphAQCk6Xdh8cYbb8SNN94Y48aNi8GDB8cJJ5wQc+fOjb1791Z7tFTf+9734vzzz49Pf/rTccwxx1R7nF574IEH4rOf/WwceeSRcd5558Wzzz5b7ZHSrFu3Lq644opobm6Ourq6eOyxx6o9Uqr29vY455xzoqGhIUaMGBFXXXVVvPzyy9UeK9WiRYti4sSJ+z90aPLkybFy5cpqj1UxCxYsiLq6upg9e3a1R0lx7733Rl1d3QHL+PHjqz1Wuo6Ojrjuuuti2LBhMXjw4Dj99NNj48aNfT5HvwuLl156Kbq7u2Px4sXxwgsvxE9+8pN48MEH45577qn2aKn27t0bM2bMiFtuuaXao/Tar3/962hra4u5c+fGc889F5MmTYrLLrssdu3aVe3RUuzZsycmTZoUDzzwQLVHqYi1a9dGa2trrF+/PlavXh3vv/9+XHrppbFnz55qj5Zm9OjRsWDBgti0aVNs3LgxLr744rjyyivjhRdeqPZo6TZs2BCLFy+OiRMnVnuUVKeddlq8+eab+5dnnnmm2iOlevfdd2PKlCnxqU99KlauXBkvvvhi/PjHP44hQ4b0/TCl/wI/+MEPSuPGjav2GBWxdOnSUlNTU7XH6JVzzz231Nrauv/2vn37Ss3NzaX29vYqTlUZEVFasWJFtceoqF27dpUiorR27dpqj1JRQ4YMKT388MPVHiNVV1dX6aSTTiqtXr269IUvfKF0xx13VHukFHPnzi1NmjSp2mNU1N1331264IILqj1GqVQqlfrdGYuD6ezsjKFDh1Z7DA5i7969sWnTppg2bdr++wYMGBDTpk2Lv/71r1WcjJ7q7OyMiOi3z7l9+/bF8uXLY8+ePTF58uRqj5OqtbU1Lr/88gOej/3Fq6++Gs3NzXH88cfHzJkzY/v27dUeKdUTTzwRZ599dsyYMSNGjBgRZ5xxRjz00ENVmaXfh8XWrVvj/vvvj2984xvVHoWD+Mc//hH79u2LY4899oD7jz322HjrrbeqNBU91d3dHbNnz44pU6bEhAkTqj1Oqi1btsTRRx8d9fX1cfPNN8eKFSvi1FNPrfZYaZYvXx7PPfdctLe3V3uUdOedd1488sgj8eSTT8aiRYti27ZtceGFF0ZXV1e1R0vz+uuvx6JFi+Kkk06KVatWxS233BK33357/OIXv+jzWWomLL797W//28U3/3956aWXDtimo6MjvvSlL8WMGTPipptuqtLkh68nxwifJK2trfH888/H8uXLqz1Kus997nOxefPm+Nvf/ha33HJLzJo1K1588cVqj5Vix44dcccdd8Qvf/nLOPLII6s9Trrp06fHjBkzYuLEiXHZZZfFH//4x3jvvffiN7/5TbVHS9Pd3R1nnnlmzJ8/P84444z4+te/HjfddFM8+OCDfT5Ln39tek9961vfiuuvv/5j1zn++OP3//POnTtj6tSpcf7558eSJUsqPF2Oco+xP/jMZz4TAwcOjLfffvuA+99+++047rjjqjQVPXHrrbfGH/7wh1i3bl2MHj262uOkGzRoUJx44okREXHWWWfFhg0b4qc//WksXry4ypP13qZNm2LXrl1x5pln7r9v3759sW7duvjZz34WxWIxBg4cWMUJcx1zzDFx8sknx9atW6s9SpqRI0f+2xm0U045JR599NE+n6VmwmL48OExfPjww1q3o6Mjpk6dGmeddVYsXbo0BgyojRMz5RxjfzFo0KA466yz4qmnnoqrrroqIj4o76eeeipuvfXW6g7HYSmVSnHbbbfFihUrYs2aNTFu3Lhqj9Qnuru7o1gsVnuMFJdcckls2bLlgPtuuOGGGD9+fNx99939KioiInbv3h2vvfZafOUrX6n2KGmmTJnyb3/m/corr8TYsWP7fJaaCYvD1dHRERdddFGMHTs2fvSjH8U777yz/2f96Tfg7du3x7/+9a/Yvn177Nu3LzZv3hwRESeeeGIcffTR1R2uTG1tbTFr1qw4++yz49xzz4377rsv9uzZEzfccEO1R0uxe/fuA34z2rZtW2zevDmGDh0aY8aMqeJkOVpbW2PZsmXx+OOPR0NDw/5rY5qammLw4MFVni7HnDlzYvr06TFmzJjo6uqKZcuWxZo1a2LVqlXVHi1FQ0PDv10Tc9RRR8WwYcP6xbUyd911V1xxxRUxduzY2LlzZ8ydOzcGDhwY1157bbVHS3PnnXfG+eefH/Pnz48vf/nL8eyzz8aSJUuqc8a+2n+Wkm3p0qWliDjo0p/MmjXroMf49NNPV3u0Hrn//vtLY8aMKQ0aNKh07rnnltavX1/tkdI8/fTTB/13NWvWrGqPluJQz7elS5dWe7Q0X/va10pjx44tDRo0qDR8+PDSJZdcUvrTn/5U7bEqqj/9uek111xTGjlyZGnQoEGlUaNGla655prS1q1bqz1Wut///velCRMmlOrr60vjx48vLVmypCpz+Np0ACBNbVx8AADUBGEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKT5H2SAGmO0vwpyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxaU6N16_-E8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}